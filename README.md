[TÃ¼rkÃ§e] FelÃ§li ve ALS HastalarÄ±nÄ±n Ä°letiÅŸimi Ä°Ã§in GeliÅŸtirilmiÅŸtir 
Merhaba
Bu projede, derin Ã¶ÄŸrenme ve bilgisayarlÄ± gÃ¶rÃ¼ algoritmalarÄ± kullanarak gÃ¶z kÄ±rpma hareketlerini gerÃ§ek zamanlÄ± olarak algÄ±layan ve Mors alfabesi Ã¼zerinden metne dÃ¶nÃ¼ÅŸtÃ¼ren uÃ§tan uca bir sistem geliÅŸtirdim.
Proje DetaylarÄ±:
ğŸ”¹ Model Mimarisi: YÃ¼z ve gÃ¶z tespiti iÃ§in OpenCV Haar Cascade yapÄ±sÄ±nÄ± ve gÃ¶zÃ¼n aÃ§Ä±k/kapalÄ± durumunu sÄ±nÄ±flandÄ±rmak iÃ§in EvriÅŸimli Sinir AÄŸlarÄ± (CNN) katmanlarÄ±nÄ± birleÅŸtiren bir yapÄ± tasarladÄ±m.
ğŸ”¹ AmaÃ§: ALS ve felÃ§li hastalar gibi motor beceri kaybÄ± yaÅŸayan bireylerin iletiÅŸimini, gÃ¶z hareketlerini otonom bir ÅŸekilde metne Ã§evirerek kolaylaÅŸtÄ±rmak.
ğŸ”¹ Teknik SÃ¼reÃ§ ve DaÄŸÄ±tÄ±m:GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme: KÄ±rpÄ±lan gÃ¶z gÃ¶rÃ¼ntÃ¼leri 64x64 boyutunda gri tonlamalÄ± matrislere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek $1/255$ oranÄ±nda normalize edildi.
Katman YapÄ±sÄ±: GÃ¶z durumunu saptamak iÃ§in Conv2D ve MaxPooling2D katmanlarÄ±, nihai sÄ±nÄ±flandÄ±rma iÃ§in Flatten ve Dense katmanlarÄ± kullanÄ±ldÄ±.
GerÃ§ek ZamanlÄ± Ã‡eviri: AlgÄ±lanan kÄ±sa ve uzun gÃ¶z kÄ±rpma sÃ¼releri analiz edilerek otonom bir ÅŸekilde anlÄ±k Mors kodu ve metin Ã¼retimi saÄŸlandÄ±.
ğŸ”¹ Performans: Model, kamera akÄ±ÅŸÄ± Ã¼zerinden yÃ¼ksek doÄŸrulukla anlÄ±k tepki verecek ÅŸekilde optimize edildi.
KullanÄ±lan Teknolojiler: Python, Keras, TensorFlow, OpenCV.
KodlarÄ± incelemek ve geliÅŸtirme Ã¶nerilerinizi paylaÅŸmak isterseniz geri bildirimleriniz benim iÃ§in Ã§ok deÄŸerli!
Yazar: Mustafa AlpergÃ¼n

[English] Developed Specifically for the Communication of Paralyzed and ALS Patients 
HelloIn 
this project, I developed an end-to-end real-time system that detects eye blink patterns using computer vision and deep learning algorithms, translating them into text via Morse code.
Project Overview:
ğŸ”¹ Model Architecture: I designed a model combining OpenCV Haar Cascades for robust face/eye detection and Convolutional Neural Networks (CNN) for high-accuracy eye state classification.
ğŸ”¹ Objective: To facilitate communication for individuals with motor skill impairments, such as ALS and paralyzed patients, by autonomously converting eye movements into text.
ğŸ”¹ Technical Pipeline:
Image Engineering: Processed cropped eye images into 64x64 grayscale arrays with $1/255$ normalization.
Layer Composition: Integrated Conv2D and MaxPooling2D layers followed by Flatten and Dense layers to classify open and closed eye states.
Real-Time Translation: Extracted chronometric data from blink durations (short/long) to autonomously generate and display Morse code and text instantly.
ğŸ”¹ Evaluation: The model was optimized to perform highly accurate real-time analysis over live video feeds.
Tech Stack: Python, Keras, TensorFlow, OpenCV.
Feel free to review the code and share your feedback!
Author: Mustafa AlpergÃ¼n
